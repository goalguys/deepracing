{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure, matplotlib.axes\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import yaml \n",
    "import tqdm\n",
    "import collections.abc\n",
    "import torch\n",
    "from utils import PredictionResults\n",
    "print(sys.version)\n",
    "print(sys.version_info)\n",
    "\n",
    "thisfiledir=os.path.abspath(\"\")\n",
    "deepracingmodelsdir = os.path.abspath(os.path.join(thisfiledir, \"..\"))\n",
    "deepracingdir = os.path.abspath(os.path.join(thisfiledir, \"..\", \"..\", \"deepracing_py\"))\n",
    "if (not (deepracingmodelsdir in sys.path)) or (not (deepracingdir in sys.path)):\n",
    "    sys.path = [deepracingmodelsdir, deepracingdir] + sys.path\n",
    "\n",
    "homedir = os.environ[\"HOME\"]\n",
    "\n",
    "mtrdir=os.path.join(homedir, \"deepracingws\", \"MTR\")\n",
    "print(mtrdir)\n",
    "if (not (mtrdir in sys.path)):\n",
    "    sys.path.insert(0, mtrdir)\n",
    "print(sys.path)\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from deepracing_models.data_loading import SubsetFlag\n",
    "import deepracing_models.math_utils as mu\n",
    "import deepracing_models.data_loading.file_datasets as FD\n",
    "import deepracing_models.data_loading.utils.file_utils as file_utils\n",
    "import torch.utils.data as torchdata\n",
    "keys : set = {\n",
    "    \"hist\",\n",
    "    \"hist_quats\",\n",
    "    \"hist_vel\",\n",
    "    \"fut\",\n",
    "    \"fut_quats\",\n",
    "    \"fut_vel\",\n",
    "    \"left_bd\",\n",
    "    \"right_bd\",\n",
    "    \"future_left_bd\",\n",
    "    \"future_right_bd\",\n",
    "    \"thistory\",\n",
    "    \"tfuture\"\n",
    "}\n",
    "dsets : list[FD.TrajectoryPredictionDataset] = \\\n",
    "    file_utils.load_datasets_from_files(\"/p/DeepRacing/unpacked_datasets/local_fitting/v1/deepracing_standard\",\n",
    "                                     flag=SubsetFlag.TEST, keys=keys)\n",
    "fulldset : torchdata.ConcatDataset = torchdata.ConcatDataset(dsets)\n",
    "\n",
    "\n",
    "bezier_experiment = \"widespread_beans_6059\"\n",
    "bezier_results_dir = os.path.join(\"/p/DeepRacing/mixnet_bezier_results\", bezier_experiment)\n",
    "bezier_results = PredictionResults.from_data_file(os.path.join(bezier_results_dir, \"data.npz\"), \"BezierMixNet\")\n",
    "bezier_results.compute_fde()\n",
    "\n",
    "# composite_experiment = \"sunny_coyote_3579\"\n",
    "composite_experiment = \"chosen_preservative_7505\"\n",
    "composite_results_dir = os.path.join(\"/p/DeepRacing/bamf_results\", composite_experiment)\n",
    "composite_results = PredictionResults.from_data_file(os.path.join(composite_results_dir, \"data.npz\"), \"BARTÃ©\")\n",
    "composite_results.compute_fde()\n",
    "composite_curves = torch.as_tensor(composite_results[\"curves\"], dtype=torch.float64, device=torch.device(\"cpu\"))\n",
    "kbezier = composite_curves.shape[-2] - 1\n",
    "num_segments = composite_curves.shape[-3]\n",
    "tfuture_np = np.stack([fulldset[i][\"tfuture\"] for i in range(len(fulldset))], axis=0)\n",
    "tfuture = torch.as_tensor(tfuture_np, dtype=composite_curves.dtype, device=composite_curves.device)\n",
    "tfuture = tfuture - tfuture[:,[0,]]\n",
    "tswitch = torch.stack([torch.linspace(tfuture[i,0], tfuture[i,-1], steps=num_segments+1, dtype=tfuture.dtype, device=tfuture.device) for i in range(tfuture.shape[0])], dim=0)\n",
    "tstart = tswitch[:,:-1]\n",
    "tend = tswitch[:,1:]\n",
    "dt = tend - tstart\n",
    "composite_curve_derivs = kbezier*(composite_curves[:,:,1:] - composite_curves[:,:,:-1])/(dt[:,:,None,None])\n",
    "vels_eval, _ = mu.compositeBezierEval(tstart, dt, composite_curve_derivs, tfuture)\n",
    "composite_results[\"vel_predictions\"] = vels_eval.cpu().numpy()\n",
    "\n",
    "\n",
    "mixnet_experiment = \"agricultural_flue_8932\"\n",
    "mixnet_results_dir = os.path.join(\"/p/DeepRacing/mixnet_results\", mixnet_experiment)\n",
    "mixnet_results = PredictionResults.from_data_file(os.path.join(mixnet_results_dir, \"data.npz\"), \"MixNet\")\n",
    "mixnet_results[\"ground_truth\"] = np.stack([fulldset[i][\"fut\"].copy() for i in range(len(fulldset))], axis=0)\n",
    "mixnet_results.compute_fde()\n",
    "\n",
    "mtr_experiment = \"formal_pedestal_9890\"\n",
    "mtr_results_dir =  os.path.join(\"/p/DeepRacing/mtr_results\", mtr_experiment)\n",
    "mtr_data_dir = \"/p/DeepRacing/unpacked_datasets/local_fitting/v1/mtr_format/1second\"\n",
    "mtr_scenarios_dir = os.path.join(mtr_data_dir, \"processed_scenarios_test\")\n",
    "mtr_sortfile = os.path.join(mtr_results_dir, \"test_plots\", \"idx_sort.npz\")\n",
    "if not os.path.isfile(mtr_sortfile):\n",
    "    with open(os.path.join(mtr_data_dir, \"processed_scenarios_test_infos.pkl\"), \"rb\") as f:\n",
    "        mtr_infos = pkl.load(f)\n",
    "    mtr_keys = mtr_infos[0].keys()\n",
    "    entries = []\n",
    "    for (idx, info) in tqdm.tqdm(enumerate(mtr_infos), total=len(mtr_infos)):\n",
    "        scenario_id = info[\"scenario_id\"]\n",
    "        with open(os.path.join(mtr_scenarios_dir, scenario_id+\".metadata.yaml\"), \"r\") as f:\n",
    "            scenario_metadata = yaml.safe_load(f)\n",
    "        deepracing_dir = os.path.dirname(scenario_metadata[\"deepracing_file\"])\n",
    "        dset_index = scenario_metadata[\"index\"]\n",
    "        car_index = int(os.path.basename(deepracing_dir).split(\"_\")[-1])\n",
    "        dated_trackname : str = os.path.basename(os.path.dirname(deepracing_dir))\n",
    "        trackname = dated_trackname.split(\"_\")[0]\n",
    "        entries.append((idx, scenario_id, trackname, car_index, dset_index))\n",
    "    entries_sorted = sorted(entries, key=lambda entry : (entry[2], entry[3], entry[4]))\n",
    "    scenario_ids_sorted = np.asarray([e[1] for e in entries_sorted], dtype=object)\n",
    "    idx_sort = np.asarray([e[0] for e in entries_sorted], dtype=np.int64)\n",
    "    with open(mtr_sortfile, \"wb\") as f:\n",
    "        np.savez(f, idx_sort=idx_sort, scenario_ids=scenario_ids_sorted)\n",
    "\n",
    "with open(mtr_sortfile, \"rb\") as f:\n",
    "    npfile = np.load(f, allow_pickle=True)\n",
    "    sort_idx_mtr = npfile[\"idx_sort\"].copy()\n",
    "    scenario_ids_sorted = npfile[\"scenario_ids\"].copy()\n",
    "\n",
    "mtr_results = PredictionResults.from_data_file(os.path.join(mtr_results_dir, \"test_plots\", \"data.npz\"), \"MTR\", sort_idx=sort_idx_mtr)\n",
    "mtr_results[\"predictions_all\"] = mtr_results[\"predictions\"].copy()\n",
    "mtr_results[\"predictions\"] = np.zeros_like(mtr_results[\"predictions_all\"][:,0])\n",
    "for idx in range(mtr_results[\"predictions_all\"].shape[0]):\n",
    "    mtr_results[\"predictions\"][idx] = mtr_results[\"predictions_all\"][idx,mtr_results[\"best_curve_idx\"][idx]]\n",
    "mtr_results.compute_fde()\n",
    "# for k in [\"history\", \"ground_truth\"]\n",
    "\n",
    "all_history = np.stack([fulldset[i][\"hist\"] for i in range(len(fulldset))], axis=0)\n",
    "all_leftbound = np.stack([fulldset[i][\"future_left_bd\"] for i in range(len(fulldset))], axis=0)\n",
    "all_rightbound = np.stack([fulldset[i][\"future_right_bd\"] for i in range(len(fulldset))], axis=0)\n",
    "for result in [bezier_results, mtr_results, composite_results, mixnet_results]:\n",
    "    result[\"left_bd\"] = all_leftbound.copy()\n",
    "    result[\"right_bd\"] = all_rightbound.copy()\n",
    "    print(\"%s has %d points\" % (result.modelname, result[\"history\"].shape[0]))\n",
    "    print(\"%s has keys: %s\" % (result.modelname, str(list(result.keys()))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from torch.utils.data import Subset\n",
    "from utils import plot_error_histograms, plot_outliers\n",
    "\n",
    "nonoutliers, _ = composite_results.trim_percentiles(metric=\"ade\", whis=2.5)\n",
    "outliers = ~nonoutliers\n",
    "print(len(fulldset))\n",
    "print(np.sum(nonoutliers))\n",
    "print(np.sum(outliers))\n",
    "\n",
    "composite_results_trimmed = composite_results.subsample(nonoutliers)\n",
    "bezier_results_trimmed = bezier_results.subsample(nonoutliers)\n",
    "mtr_results_trimmed = mtr_results.subsample(nonoutliers)\n",
    "mixnet_results_trimmed = mixnet_results.subsample(nonoutliers)\n",
    "fulldset_trimmed = Subset(fulldset, np.where(nonoutliers)[0])\n",
    "\n",
    "\n",
    "# print(np.sum(mtr_nonoutliers*(~barte_nonoutliers)))\n",
    "# print(np.sum(barte_nonoutliers*(~mtr_nonoutliers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "rcparams_latex = {\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "}\n",
    "\n",
    "results_base = \"/p/DeepRacing/trajectory_prediction_results/sim_data\"\n",
    "plots_dir = os.path.join(results_base, \"plots\")\n",
    "histograms_dir = os.path.join(results_base, \"histograms\")\n",
    "plots_dir_trimmed = os.path.join(results_base, \"plots_trimmed\")\n",
    "histograms_dir_trimmed = os.path.join(results_base, \"histograms_trimmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_table\n",
    "from texttable import Texttable\n",
    "\n",
    "results_textable = create_table([composite_results, mtr_results, mixnet_results, bezier_results])\n",
    "results_textable.set_deco(Texttable.BORDER | Texttable.HLINES | Texttable.HEADER | Texttable.VLINES)\n",
    "print(results_textable.draw())\n",
    "results_trimmed_textable = create_table([composite_results_trimmed, mtr_results_trimmed, mixnet_results_trimmed, bezier_results_trimmed])\n",
    "results_trimmed_textable.set_deco(Texttable.BORDER | Texttable.HLINES | Texttable.HEADER | Texttable.VLINES)\n",
    "print(results_trimmed_textable.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "metric=\"ade\"\n",
    "maindir = \"/p/DeepRacing/trajectory_prediction_results/sim_data/cross_error_analysis\"\n",
    "basedir = os.path.join(maindir, metric)\n",
    "all_results_composite_ref = [composite_results, mtr_results, mixnet_results, bezier_results]\n",
    "all_results_mtr_ref = [mtr_results, composite_results, mixnet_results, bezier_results]\n",
    "\n",
    "cross_error_analysis(all_results_composite_ref, fulldset, basedir, p0=None, metric=metric)\n",
    "cross_error_analysis(all_results_mtr_ref, fulldset, basedir, p0=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "cross_error_analysis(all_results_composite_ref, fulldset, basedir, other_models=[mtr_results.modelname,], metric=metric)\n",
    "cross_error_analysis(all_results_mtr_ref, fulldset, basedir, other_models=[composite_results.modelname,], metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_samples = composite_results[metric].shape[0]\n",
    "barte_nonoutliers, barte_maxval = composite_results.trim_percentiles(metric=metric)\n",
    "mtr_nonoutliers, mtr_maxval = mtr_results.trim_percentiles(metric=metric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "\n",
    "\n",
    "barte_outliers = ~barte_nonoutliers\n",
    "mtr_outliers = ~mtr_nonoutliers\n",
    "both_bad = barte_outliers*mtr_outliers\n",
    "barte_both_bad = composite_results.subsample(both_bad)\n",
    "mtr_both_bad = mtr_results.subsample(both_bad)\n",
    "dset_both_bad : torchdata.Subset = torchdata.Subset(fulldset, np.where(both_bad)[0])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_bad_merged\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_bad, barte_both_bad], dset_both_bad, basedir, p0=None, metric=metric)\n",
    "cross_error_analysis([barte_both_bad, mtr_both_bad], dset_both_bad, basedir, p0=None, metric=metric, histograms=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "from utils import cross_error_analysis\n",
    "\n",
    "\n",
    "barte_outliers = composite_results[metric]>barte_maxval\n",
    "mtr_outliers = mtr_results[metric]>barte_maxval\n",
    "both_bad = barte_outliers*mtr_outliers\n",
    "barte_both_bad = composite_results.subsample(both_bad)\n",
    "mtr_both_bad = mtr_results.subsample(both_bad)\n",
    "dset_both_bad : torchdata.Subset = torchdata.Subset(fulldset, np.where(both_bad)[0])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_bad_barte_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_bad, barte_both_bad], dset_both_bad, basedir, p0=None, metric=metric)\n",
    "cross_error_analysis([barte_both_bad, mtr_both_bad], dset_both_bad, basedir, p0=None, metric=metric, histograms=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barte_outliers = composite_results[metric]>mtr_maxval\n",
    "mtr_outliers = mtr_results[metric]>mtr_maxval\n",
    "both_bad = barte_outliers*mtr_outliers\n",
    "barte_both_bad = composite_results.subsample(both_bad)\n",
    "mtr_both_bad = mtr_results.subsample(both_bad)\n",
    "dset_both_bad : torchdata.Subset = torchdata.Subset(fulldset, np.where(both_bad)[0])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_bad_mtr_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_bad, barte_both_bad], dset_both_bad, basedir, p0=None, metric=metric)\n",
    "cross_error_analysis([barte_both_bad, mtr_both_bad], dset_both_bad, basedir, p0=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "barte_inliers = composite_results[metric]<=barte_maxval \n",
    "mtr_inliers = mtr_results[metric]<=mtr_maxval\n",
    "both_good = barte_inliers*mtr_inliers\n",
    "\n",
    "barte_both_good = composite_results.subsample(both_good)\n",
    "mtr_both_good = mtr_results.subsample(both_good)\n",
    "\n",
    "dset_both_good : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_good.shape[0]) if both_good[i]])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_good_merged\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_good, barte_both_good], dset_both_good, basedir, p0=None, metric=metric)\n",
    "cross_error_analysis([barte_both_good, mtr_both_good], dset_both_good, basedir, p0=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barte_inliers = composite_results[metric]<=barte_maxval \n",
    "mtr_inliers = mtr_results[metric]<=barte_maxval\n",
    "both_good = barte_inliers*mtr_inliers\n",
    "\n",
    "barte_both_good = composite_results.subsample(both_good)\n",
    "mtr_both_good = mtr_results.subsample(both_good)\n",
    "\n",
    "dset_both_good : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_good.shape[0]) if both_good[i]])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_good_barte_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_good, barte_both_good], dset_both_good, basedir, p0=None, metric=metric)\n",
    "cross_error_analysis([barte_both_good, mtr_both_good], dset_both_good, basedir, p0=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barte_inliers = composite_results[metric]<=mtr_maxval\n",
    "mtr_inliers = mtr_results[metric]<=mtr_maxval\n",
    "both_good = barte_inliers*mtr_inliers\n",
    "\n",
    "barte_both_good = composite_results.subsample(both_good)\n",
    "mtr_both_good = mtr_results.subsample(both_good)\n",
    "\n",
    "dset_both_good : torchdata.Subset = torchdata.Subset(fulldset, [i for i in range(both_good.shape[0]) if both_good[i]])\n",
    "basedir = os.path.join(os.path.dirname(maindir), \"both_models_good_mtr_maxval\", metric)\n",
    "os.makedirs(basedir, exist_ok=True)\n",
    "cross_error_analysis([mtr_both_good, barte_both_good], dset_both_good, basedir, p0=None, metric=metric)\n",
    "cross_error_analysis([barte_both_good, mtr_both_good], dset_both_good, basedir, p0=None, metric=metric, histograms=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# idx_good = plot_outliers([composite_results, mtr_results, mixnet_results, bezier_results], plots_dir, fulldset, N=25, metric_key=\"ade\", worst=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sample = fulldset[idx_good[26]]\n",
    "from scipy.spatial.transform import Rotation\n",
    "from matplotlib.collections import LineCollection, Collection\n",
    "from matplotlib.colors import BoundaryNorm, ListedColormap, Colormap\n",
    "from matplotlib.legend_handler import HandlerLineCollection\n",
    "import matplotlib.cm\n",
    "class HandlerColorLineCollection(HandlerLineCollection):\n",
    "    def create_artists(self, legend, artist ,xdescent, ydescent,\n",
    "                        width, height, fontsize,trans):\n",
    "        x = np.linspace(0,width,self.get_numpoints(legend)+1)\n",
    "        y = np.zeros(self.get_numpoints(legend)+1)+height/2.-ydescent\n",
    "        points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "        segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "        lc = LineCollection(segments, cmap=artist.cmap,\n",
    "                     transform=trans, linestyle=artist.get_linestyle())\n",
    "        lc.set_array(x)\n",
    "        lc.set_linewidth(artist.get_linewidth())\n",
    "        return [lc]\n",
    "def add_colored_line(points : np.ndarray, cvals : np.ndarray, ax : matplotlib.axes.Axes, cmap : str | Colormap, \n",
    "    linestyle=\"solid\", alpha=1.0) -> tuple[LineCollection, Collection]:\n",
    "    points_exp = points.reshape(-1, 1, points.shape[-1])\n",
    "    segments = np.concatenate([points_exp[:-1], points_exp[1:]], axis=1)\n",
    "    norm = plt.Normalize(cvals.min(), cvals.max())\n",
    "    lc = LineCollection(segments, cmap=cmap, norm=norm,linestyle=linestyle, alpha=alpha)\n",
    "    \n",
    "    lc.set_array(cvals)\n",
    "    line = ax.add_collection(lc)\n",
    "    return lc, line\n",
    "\n",
    "sample = fulldset[idx_mtr_bad_ade[7]]\n",
    "print(sample.keys())\n",
    "\n",
    "Rmat = Rotation.from_rotvec([0.0, 0.0, 0.5*np.pi]).as_matrix()[0:2,0:2]\n",
    "history_start = 0\n",
    "thistory = sample[\"thistory\"]\n",
    "history = (Rmat @ sample[\"hist\"][history_start:,[0,1]].T).T\n",
    "history_vels = sample[\"hist_vel\"][:,[0,1]]\n",
    "history_speeds = np.linalg.norm(history_vels, ord=2.0, axis=1)\n",
    "\n",
    "tfuture = sample[\"tfuture\"]\n",
    "ground_truth = (Rmat @ sample[\"fut\"][:,[0,1]].T).T\n",
    "ground_truth_vels = sample[\"fut_vel\"][:,[0,1]]\n",
    "ground_truth_speeds = np.linalg.norm(ground_truth_vels, ord=2.0, axis=1)\n",
    "\n",
    "all_points = np.concatenate([history, ground_truth], axis=0)\n",
    "all_speeds = np.concatenate([history_speeds, ground_truth_speeds], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "future_left_bd = (Rmat @ sample[\"future_left_bd\"][:,[0,1]].T).T\n",
    "future_right_bd = (Rmat @ sample[\"future_right_bd\"][:,[0,1]].T).T\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "asdf : tuple[matplotlib.figure.Figure, matplotlib.axes.Axes] = plt.subplots(1,1)\n",
    "fig : matplotlib.figure.Figure = asdf[0]\n",
    "ax : matplotlib.axes.Axes = asdf[1]\n",
    "norm = plt.Normalize(all_speeds.min(), all_speeds.max(), clip=True)\n",
    "cmap = \"RdYlGn\"\n",
    "scalar_mappable = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "lc_hist, line_hist = add_colored_line(history, history_speeds[:-1], ax, cmap, linestyle=\"dotted\")\n",
    "lc_ground_truth, line_ground_truth  = add_colored_line(ground_truth, ground_truth_speeds[:-1], ax, cmap)\n",
    "line_ground_truth.set_label(\"asdf\")\n",
    "lc_ground_truth.set_label(\"asdf\")\n",
    "# lc_fake, line_fake  = add_colored_line(all_points, all_speeds[:-1], ax, cmap, alpha=0.25)\n",
    "\n",
    "# ax.plot(history[:,0], history[:,1], linestyle=\"--\", color=history_speeds, cmap=\"viridis\", norm=norm, alpha=0.5, label=\"History\")\n",
    "# ax.plot(ground_truth[:,0], ground_truth[:,1], linestyle=\"dotted\", color=\"black\", label=\"Ground Truth\")\n",
    "ax.plot(future_left_bd[:,0], future_left_bd[:,1], linestyle=\"solid\", color=\"black\")\n",
    "boundaries = ax.plot(future_right_bd[:,0], future_right_bd[:,1], linestyle=\"solid\", color=\"black\")\n",
    "ax.axis(\"equal\")\n",
    "ax.legend([\n",
    "            #    lc_hist, \n",
    "            #    lc_ground_truth,\n",
    "               boundaries[0],\n",
    "           ],\n",
    "           [\n",
    "        #    [   \"History\", \n",
    "        #        \"Ground Truth\", \n",
    "               \"Boundaries\",\n",
    "           ], loc=(0.25, 0.5),\n",
    "          handler_map={\n",
    "              lc_hist: HandlerColorLineCollection(numpoints=4),\n",
    "              lc_ground_truth: HandlerColorLineCollection(numpoints=4),\n",
    "\n",
    "            },\n",
    "            framealpha=1)\n",
    "fig.colorbar(scalar_mappable, ax=ax)\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(plots_dir, \"label.svg\"), pad_inches=0.02)\n",
    "fig.savefig(os.path.join(plots_dir, \"label.pdf\"), pad_inches=0.02)\n",
    "# fig2  = plt.figure()\n",
    "# plt.plot(thistory, history_speeds)\n",
    "# plt.plot(tfuture, ground_truth_speeds)\n",
    "plt.show()\n",
    "print(history_speeds)\n",
    "# plt.close(fig=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python310_13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
